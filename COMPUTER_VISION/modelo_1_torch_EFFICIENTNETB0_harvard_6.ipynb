{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso de EfficientNet-B0 para clasificación de melanoma utilizando la base de datos de Harvard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusión\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"¿GPU disponible?:\", torch.cuda.is_available())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No hay GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Definir transformaciones para aumentar los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Tamaño estándar de ResNet50\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalización\n",
    "])\n",
    "\n",
    "# Definir directorios\n",
    "base_dir = r\"C:\\Users\\jakif\\CODE\\PROYECTO-FINAL\\images\\PREPROCESSED_DATA_copy\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Directorios para cada clase\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Crear DataLoaders para entrenamiento y prueba\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Clases\n",
    "print(\"Clases:\", train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Cargar modelo preentrenado\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", device)\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)  # Cargar EfficientNet-B0 preentrenado\n",
    "\n",
    "# Cambiar la última capa para que coincida con el número de clases\n",
    "num_classes = len(train_dataset.classes)  # Número de clases en el conjunto de datos\n",
    "\n",
    "\n",
    "\n",
    "# Cambiar la última capa para que coincida con el número de clases\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)  # Cambiar la última capa para que coincida con el número de clases\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Definir función de pérdida y optimizador con weight decay\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Aumenté lr y añadí regularización\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=30):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'train_recall': [],\n",
    "        'train_precision': [],\n",
    "        'train_f1': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_recall': [],\n",
    "        'val_precision': [],\n",
    "        'val_f1': [],\n",
    "        'lr': []  # Para trackear el learning rate\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_patience = 5\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # Variables para métricas de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        true_positives = 0\n",
    "        predicted_positives = 0\n",
    "        total_positives = 0\n",
    "\n",
    "        # Entrenamiento con mixed precision\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            \n",
    "            # Añadido label smoothing para mejorar generalización\n",
    "            loss = criterion(outputs, labels * 0.9 + 0.05)  # Label smoothing\n",
    "            \n",
    "            loss.backward()\n",
    "            # Añadido gradient clipping para evitar exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "                preds = torch.round(torch.sigmoid(outputs))  # Aplicamos sigmoid aquí para métricas\n",
    "                \n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                true_positives += ((preds == 1) & (labels == 1)).sum().item()\n",
    "                predicted_positives += (preds == 1).sum().item()\n",
    "                total_positives += (labels == 1).sum().item()\n",
    "\n",
    "        # Cálculo de métricas de entrenamiento\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_recall = true_positives / (total_positives + 1e-6)\n",
    "        train_precision = true_positives / (predicted_positives + 1e-6)\n",
    "        train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall + 1e-6)\n",
    "        \n",
    "        # Guardar métricas de entrenamiento\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['train_f1'].append(train_f1)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_true_positives = 0\n",
    "        val_predicted_positives = 0\n",
    "        val_total_positives = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.round(torch.sigmoid(outputs))\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                val_true_positives += ((preds == 1) & (labels == 1)).sum().item()\n",
    "                val_predicted_positives += (preds == 1).sum().item()\n",
    "                val_total_positives += (labels == 1).sum().item()\n",
    "\n",
    "        # Cálculo de métricas de validación\n",
    "        val_loss = val_loss / len(test_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        val_recall = val_true_positives / (val_total_positives + 1e-6)\n",
    "        val_precision = val_true_positives / (val_predicted_positives + 1e-6)\n",
    "        val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall + 1e-6)\n",
    "        \n",
    "        # Guardar métricas de validación\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Ajustar learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Current LR: {scheduler.get_last_lr()[0]:.6f}\")  \n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Guardar el mejor modelo\n",
    "            torch.save(model.state_dict(), 'best_model_EFFICIENTB0.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}!\")\n",
    "                break\n",
    "\n",
    "        # Imprimir progreso\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%, Recall: {train_recall:.2f}, Precision: {train_precision:.2f}, F1: {train_f1:.2f}\")\n",
    "        print(f\"Val - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%, Recall: {val_recall:.2f}, Precision: {val_precision:.2f}, F1: {val_f1:.2f}\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Cargar el mejor modelo antes de retornar\n",
    "    model.load_state_dict(torch.load('best_model_EFFICIENTB0.pth'))\n",
    "    print(\"Entrenamiento completado\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(model, train_loader, test_loader, criterion, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Gráfico de pérdida\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gráfico de accuracy\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gráfico de recall\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(history['train_recall'], label='Train Recall')\n",
    "    plt.plot(history['val_recall'], label='Val Recall')\n",
    "    plt.title('Recall')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gráfico de precision\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(history['train_precision'], label='Train Precision')\n",
    "    plt.plot(history['val_precision'], label='Val Precision')\n",
    "    plt.title('Precision')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gráfico de F1\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(history['train_f1'], label='Train F1')\n",
    "    plt.plot(history['val_f1'], label='Val F1')\n",
    "    plt.title('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar gráficos\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Matriz de Confusión\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluar el modelo\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Modo evaluación\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(images).squeeze()\n",
    "            preds = torch.round(torch.sigmoid(outputs))  # Convertir logits en 0 o 1\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluar el modelo\n",
    "all_labels, all_preds = evaluate_model(model, test_loader)\n",
    "# Imprimir métricas\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=train_dataset.classes))\n",
    "# Graficar matriz de confusión\n",
    "plot_confusion_matrix(all_labels, all_preds, classes=train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'melanoma_model_1_torch_EFFICIENTNETB0_harvard.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    model.eval()\n",
    "    img = Image.open(image_path)\n",
    "    img = transform(img).unsqueeze(0).to(device)  # Aplicar las mismas transformaciones\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img).squeeze()\n",
    "        prediction = torch.sigmoid(output).item()\n",
    "    \n",
    "    if prediction > 0.5:\n",
    "        print(\"🔴 Malignant melanoma\")\n",
    "    else:\n",
    "        print(\"🟢 Benign melanoma\")\n",
    "\n",
    "# Prueba con una imagen nueva\n",
    "predict_image(r'C:\\Users\\jakif\\CODE\\PROYECTO-FINAL\\images\\harvard_dataset\\PREPROCESSED_DATA\\final\\train\\benign_images\\ISIC_0024306.jpg', model)  # Benigno\n",
    "predict_image(r'C:\\Users\\jakif\\CODE\\PROYECTO-FINAL\\images\\harvard_dataset\\PREPROCESSED_DATA\\final\\test\\malignant_images\\ISIC_0034529.jpg', model)  # Maligno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacion gradcam\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "#clase GradCam\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # Register hooks for gradients and activations\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_full_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def get_cam(self):\n",
    "        # Ensure gradients and activations are available\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            raise ValueError(\"Gradients or activations are not available. Perform a backward pass first.\")\n",
    "\n",
    "        # Move gradients and activations to the same device\n",
    "        device = self.activations.device\n",
    "        gradients = self.gradients.to(device)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        weights = torch.mean(gradients, dim=[0, 2, 3])\n",
    "        cam = torch.zeros(self.activations.shape[2:], dtype=torch.float32, device=device)\n",
    "\n",
    "        for i in range(weights.shape[0]):\n",
    "            cam += weights[i] * self.activations[0, i, :, :]\n",
    "\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam - torch.min(cam)\n",
    "        cam = cam / torch.max(cam)\n",
    "        return cam.cpu().detach().numpy()\n",
    "  \n",
    "# Load the model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)  # 1 neuron for binary classification\n",
    "model.load_state_dict(torch.load('melanoma_model_1_torch_RESNET50_harvard.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# Get the target layer\n",
    "target_layer = model.layer4[2].conv3  # Last convolutional layer\n",
    "# Create the GradCam object\n",
    "grad_cam = GradCam(model, target_layer)\n",
    "# Load and preprocess the image\n",
    "image_path = r'C:\\Users\\jakif\\CODE\\PROYECTO-FINAL\\images\\harvard_dataset\\PREPROCESSED_DATA\\final\\test\\malignant_images\\ISIC_0034529.jpg'\n",
    "image = Image.open(image_path)\n",
    "image = transform(image).unsqueeze(0).to(device)  # Apply the same transformations\n",
    "# Forward pass\n",
    "output = model(image)\n",
    "# Get the predicted class\n",
    "predicted_class = torch.round(torch.sigmoid(output)).item()\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "# Backward pass\n",
    "output[0, 0].backward()  # Backpropagate the score for the predicted class\n",
    "# Get the gradients and activations\n",
    "gradients = grad_cam.gradients\n",
    "activations = grad_cam.activations\n",
    "# Get the CAM\n",
    "cam = grad_cam.get_cam()\n",
    "# Resize the CAM to the original image size\n",
    "original_image = Image.open(image_path)\n",
    "original_image = original_image.resize((224, 224))\n",
    "cam = cv2.resize(cam, (original_image.size[0], original_image.size[1]))\n",
    "# Normalize the CAM\n",
    "cam = cam - np.min(cam)\n",
    "cam = cam / np.max(cam)\n",
    "# Convert the CAM to a heatmap\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "# Convert the heatmap to BGR\n",
    "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "# Convert the original image to numpy array\n",
    "original_image = np.array(original_image)\n",
    "# Overlay the heatmap on the original image\n",
    "overlay = cv2.addWeighted(original_image, 0.5, heatmap, 0.5, 0)\n",
    "# Display the overlay\n",
    "plt.imshow(overlay)\n",
    "plt.axis('off')\n",
    "plt.title(\"Grad-CAM Overlay\")\n",
    "plt.show()\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMPUTER_VISION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
