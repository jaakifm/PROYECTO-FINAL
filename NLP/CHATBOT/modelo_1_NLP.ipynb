{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakif\\anaconda3\\envs\\modelo_1_NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "import pypdf\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import gradio as gr\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proving GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Charge a pretrained model for question answering to use GPU\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract context through papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_papers(pdf_folder):\n",
    "    texts = []\n",
    "    for file in os.listdir(pdf_folder):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder, file)\n",
    "            with open(pdf_path, \"rb\") as f:\n",
    "                reader = pypdf.PdfReader(f)\n",
    "                text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "                texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# Extract text from papers\n",
    "pdf_folder = \"C:\\PROYECTO_FINAL\\dataset_papers\"\n",
    "papers_text = extract_text_from_papers(pdf_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakif\\AppData\\Local\\Temp\\ipykernel_5768\\2331638720.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Index texts with FAISS\n",
    "db = FAISS.from_texts(papers_text, embeddings)\n",
    "db.save_local(\"faiss_melanoma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creation of the chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_respuesta(pregunta):\n",
    "    # Cargar la base de datos FAISS\n",
    "    db = FAISS.load_local(\"faiss_melanoma\", embeddings, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    # Buscar en los papers\n",
    "    docs = db.similarity_search(pregunta, k=3)  # Obtener los 3 textos más relevantes\n",
    "    contexto = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Obtener la mejor respuesta con el modelo de QA\n",
    "    respuesta = qa_pipeline(question=pregunta, context=contexto)\n",
    "    \n",
    "    return respuesta['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def chatbot_melanoma(pregunta):\n",
    "    respuesta = buscar_respuesta(pregunta)\n",
    "    return respuesta\n",
    "\n",
    "interfaz = gr.Interface(\n",
    "    fn=chatbot_melanoma,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Chatbot de Melanomas\",\n",
    "    description=\"Haz preguntas sobre melanomas basadas en papers científicos.\",\n",
    ")\n",
    "\n",
    "interfaz.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelo_1_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
